# 开发计划

## 已实现：无

## 当前任务：支持工具的动态增删

### 1. 重构 `arg_generation.py` 以支持复用

**目标**：将批量处理工具信息的逻辑分解为可处理单个工具的、可复用的函数。

**文件**：`baseline/mcp_copilot/arg_generation.py`

-   **指南 1**：将 `McpArgGenerator` 类中的核心逻辑（如 `_get_embedding`, `_generate_summary`, `_format_tool_parameters`）提取成独立的、可复用的 `async` 函数。
-   **指南 2**：创建一个新的核心函数 `process_single_server_dynamically`。此函数接收单个服务器的已验证信息，并调用上述独立的辅助函数来完成摘要生成、嵌入创建和数据格式化的完整流程。它将作为 `Router` 中 `add_tool` 方法的主要数据处理单元。
-   **指南 3 & 4**：调整原有的 `generate` 和 `run_generation` 方法。它们现在可以调用新的 `process_single_server_dynamically` 函数来处理批量任务，但其在项目启动时的调用（见 `server.py` 的修改）应被重新评估或移除。

### 2. 改造 `Router` 类以实现动态管理

**目标**：修改 `Router` 类，使其成为动态工具集的“大脑”，负责在内存中维护和管理所有工具。

**文件**：`baseline/mcp_copilot/router.py`

-   **指南 1 & 2**：修改 `__init__` 方法。不再完全依赖静态配置文件，而是初始化一个空的、内存中的 `self.servers` 字典来存储服务器配置。可以保留从 `clean_config.json` 加载初始工具集的逻辑，但核心是为动态增删做准备。
-   **指南 3 & 4**：移除对 `mcp_arg_...json` 静态数据文件的直接依赖。在 `__init__` 中，`ToolMatcher` 应通过 `self.matcher.load_data([])` 加载一个空的数据结构，等待运行时动态填充。
-   **指南 5**：实现 `add_tool` 方法。这是动态化的关键。
    -   它接收新服务器的配置和描述。
    -   **步骤 1**：（需要实现）调用一个函数（可基于 `utils/connect_mcp_server.py` 的逻辑重构）来连接并验证新服务器，获取其工具列表。
    -   **步骤 2**：（需要实现）调用在 `arg_generation.py` 中重构好的 `process_single_server_dynamically` 函数，处理上一步获取的工具信息，生成摘要和嵌入。
    -   **步骤 3**：（需要实现）将新的服务器配置存入 `self.servers`，并将处理好的工具数据添加到 `ToolMatcher` 中（**注意**: 这需要在 `ToolMatcher` 类中额外实现一个如 `add_server_info` 的方法）。
-   **指南 6**：实现 `remove_tool` 方法。
    -   它接收要移除的服务器名称。
    -   **步骤 1**：（需要实现）从 `self.servers` 字典中删除对应的服务器配置。
    -   **步骤 2**：（需要实现）从 `ToolMatcher` 中移除该服务器的所有相关数据（**注意**: 这需要在 `ToolMatcher` 类中额外实现一个如 `remove_server_info` 的方法）。

### 3. 在 `server.py` 中暴露动态接口

**目标**：创建新的 Agent 工具，让 Agent 能够通过调用自己的能力来管理其工具集。

**文件**：`baseline/mcp_copilot/server.py`

-   **指南 1**：在 `serve` 函数的开头，注释掉或移除对 `asyncio.run(run_generation())` 的调用。因为工具管理已变为动态，不再需要在启动时进行静态索引。
-   **指南 2**：创建一个名为 `add_new_tool` 的新 Agent 工具。
    -   该工具接收 `server_name`, `server_config` (JSON 字符串) 和 `server_description` 作为参数。
    -   其实现会调用 `Router` 实例上的 `add_tool` 方法，将参数传递过去，从而完成新工具的动态添加。
-   **指南 3**：创建一个名为 `remove_existing_tool` 的新 Agent 工具。
    -   该工具接收 `server_name` 作为参数。
    -   其实现会调用 `Router` 实例上的 `remove_tool` 方法，完成工具的动态移除。

## 任务设计

对于一个工具而言，它能发生的所有变化就是新增、移除和更新。问题是，如何模拟这些变化（尤其是更新，如果只是更新工具的描述，LLM 往往不会受影响），以及如何设计合适的任务来针对性地考察模型的持续学习能力

- **初始化**：给定初始的 200 个工具，作为已掌握的知识
    
    有一个小问题，是随机选出 200 个，还是每次都给一样的？随机选、多次取平均显然更公平，但是否过于消耗算力？如果过于消耗算力、但又想保持随机，是否可以减少每次新增工具的个数，这样就相当于增加了随机循环的轮次，但总开销保持不变
    
- **新增**：新增 100 个工具，模拟新技能的学习
    
    可能的评测指标：
    
    - **Learning Rate**：新知识的学习速度
    - **Retention Rate**：旧知识的保留率
- **移除**：移除 50 个工具
    
    考察模型如何应对已失效的知识。可以采用模拟报错的方式，或者直接维护一个可用的工具列表（但这样对 LLM 来说应该太简单了。我认为模拟报错更符合日常使用情况，LLM 面对报错需要弃用原有的工具，尝试采用其他方法实现）
    
    可能的评测指标：
    
    - **Error Recovery Rate**：修正次数 / 调用失效工具的次数（修正次数指的是模型在一次调用失效工具后，自我调整并最终完成任务的次数）。检查模型能否从调用失效工具中自我修正
    - **Obsolete Tool Recall**：调用失效工具次数 / 总调用次数。检查模型是否屡教不改
    - **Adaptation Delay**：从发现工具失效到成功调用新工具的平均时间或响应次数
    - **Selective Forgetting Score**：旧工具弃用后，agent 是否主动更新记忆（比较 task $N$ 和 task $N + 1$ 的调用分布，或比较第 $t$ 和 $t+1$ 轮循环同一个任务的调用分布）
    
    问题来了，如何保证移除了部分工具后，这个任务还可以实现？如果任务已经不能实现了，那 LLM 要么一直试图调用失效的工具，要么产生一个幻觉的结果，但这样会导致我们设计的指标出现问题
    
    对于复杂的问题，很难给出一个唯一的工具依赖。因此，我提议放弃任务的多工具属性，为每个工具设计一个任务。但这样工具移除后模型就无法完成任务了，这一条评测方式也就失效了
    
- **更新**：更新 50 个工具，更新参数接口 / 将工具迁移到新 server
    - **描述**：改变工具的使用说明和示例。更改描述很可能对 LLM 不起作用，因为语义没有发生变化，而 LLM 对语法的变化并不敏感
    - **接口**：修改参数、参数名、必选字段、默认值等
    - **返回结果**：修改返回格式或含义（如何实现？）、添加随机延时？

**其他需求**：Agent 的学习和遗忘曲线的可视化

## 一些实现细节

- **如何判定任务是否实现**：参考 LiveMCPBench，每个任务配有 key points 作为必须子步骤。并由 LLM 根据任务描述、key points 判断 agent 是否完成任务（论文中由人工标注验证了 LLM 的一致性）
    
    这样的实现存在一个问题，就是 LLM 的准确度依旧堪忧（Which 在 LiveMCPBench 中也有提到）。是否存在一种方法，让调用的结果有唯一正确解（或者至少存在某种直接的评判方式，而非通过模棱两可的 LLM 来判断），并且保留任务多步、多工具的属性？
    
    其次，任务的个数也不够，不满足多轮循环的要求。而且，如果工具的顺序是随机的，如果不调整相应的任务，可能会出现分配的任务无法实现的情况。因此，是否需要构建一个任务-工具依赖，用图算法来保证依赖始终满足？还是说可以放弃工具顺序的随机性，将它们固定下来？或者放弃任务的多工具属性，为每个工具设计一个相应的任务？（但这样似乎有些太简单了。优点是，依赖唯一确定，非常容易实现，可以让 LLM 将每个工具的一个示例转化为自然语言，这样正确答案就是那个示例）